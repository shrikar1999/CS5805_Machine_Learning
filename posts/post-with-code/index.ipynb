{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Classification of Spotify songs into genres\"\n",
        "author: \"Shrikar Banagiri\"\n",
        "date: \"2023-11-11\"\n",
        "categories: [news, code, analysis]\n",
        "image: \"image.jpg\"\n",
        "execute: \n",
        "  echo: false\n",
        "  freeze: true\n",
        "---"
      ],
      "id": "a220f172"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Introduction** \n",
        "\n",
        "This [Spotify song dataset](https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs/?select=spotify_songs.csv) contains over 30,000 songs from artists of different genres. Each song has specific attributes which help the user discern its genre. These attributes include `danceability`, `energy`, `loudness`, `key`, `mode`, `speechiness`, `acousticness`, `instrumentalness`, `liveness`, `valence`, and `tempo`.\n",
        "\n",
        "The problem statement is to classify the songs (based on the above attributes) into six genres: `pop`, `rock`, `latin`, `EDM`, `rap`, and `R&B`.\n",
        "\n",
        "```{}\n",
        "```\n",
        "\n",
        "## Importing the dataset\n",
        "\n",
        "First, we import the libraries required to perform the initial data analysis. The dataset, hosted on [Kaggle](https://www.kaggle.com/), is imported and stored in the variable `spotify_songs`.\n"
      ],
      "id": "564f401c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true \n",
        "\n",
        "# Import the libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Downloading and opening the dataset\n",
        "\n",
        "csv_path = Path('datasets/archive.zip') # store the dataset in a local folder\n",
        "url = 'https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs/download?datasetVersionNumber=2' # url to download the dataset\n",
        "\n",
        "if not csv_path.is_file(): # check if the dataset directory exists. \n",
        "  Path(\"datasets\").mkdir(parents=True,exist_ok=True) # Create the directory\n",
        "  urllib.request.urlretrieve(url, csv_path)\n",
        "  with zipfile.ZipFile(csv_path) as spotify_file:\n",
        "    spotify_file.extractall(path='datasets')\n",
        "    \n",
        "spotify_songs = pd.read_csv(Path('datasets/spotify_songs.csv')) # Store the dataset in a variable"
      ],
      "id": "12209771",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing the Data\n",
        "\n",
        "Let's look at the non-null entries in the dataset using the `info()` method below.\n"
      ],
      "id": "bf4926bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_songs.info()"
      ],
      "id": "4f0b804e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output shows that the columns `track_name`, `track_artist`, and `track_album_name` have 5 null elements (i.e., they only have 32828 elements). Let's look at the genres and their counts in the dataset.\n"
      ],
      "id": "5b2d28d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_songs['playlist_genre'].value_counts()"
      ],
      "id": "c6f00dcd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now look at how different genres compare on the basis of each attribute. But first, we notice that the features have wildly different scales. For example, `loudness` varies from -46.448 to 1.275 whereas tempo ranges from 0 to 1 (see histogram below). Therefore, we must standardize these attributes using the `StandardScaler`. Furthermore, features such as `valence` and `instrumentalness` have very long tails. To convert these attributes to \"gaussian\" like features, we will use the `boxcox` class from `scipy`.\n"
      ],
      "id": "5b0be2b2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_features = spotify_songs.loc[:,['danceability','energy','loudness','speechiness','acousticness','instrumentalness','liveness','valence','tempo']]\n",
        "spotify_features.hist(bins=50, figsize=(12, 8))\n",
        "plt.show()"
      ],
      "id": "b65d2d9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following violin plot also describes the relationship between some of the attributes and genres. From the first violin plot, it is evident that `rap` music has a higher `danceability` score on average while the most danceable song belongs to the `edm` genre.\n"
      ],
      "id": "312dc36b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "sns.violinplot(x=spotify_songs.playlist_genre,y=spotify_songs.danceability)\n",
        "plt.grid()\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Danceability score')\n",
        "plt.show()"
      ],
      "id": "e0e09988",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We should also look for any correlations within the features themselves. Ideally, all our features (i.e., attributes) must be independent of each other. However, it may happen that two or more features are highly correlated within themselves. In such a scenario, we will need to drop one of the correlated attributes.\n"
      ],
      "id": "d54d7741"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "sns.heatmap(spotify_features.corr(), annot=True, cmap='YlGnBu', vmin=-1, vmax=1, center=0, ax=ax)\n",
        "plt.title('Linear Correlations between attributes')\n",
        "plt.show()"
      ],
      "id": "f195991e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the correlation matrix, we can note that the attributes `energy` and `loudness` are highly correlated. Their correlation coefficient is 0.68. Thus, we will drop the `loudness` attribute.\n",
        "\n",
        "## Preprocessing the data\n",
        "\n",
        "We will first drop the `loudness` attribute since it is highly correlated with the `energy` attribute.\n"
      ],
      "id": "15704fb2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_songs = spotify_songs.drop('loudness',axis=1)"
      ],
      "id": "27da76e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The column `playlist_subgenre` has attributes such as dance pop and pop edm which are subsets of the parent column `playlist_genre`. Similarly,the `track_id`, `track_name`, `track_artist`, `track_popularity`, `track_album_id`, `track_album_name`, and `track_album_release_date` are not relevant. Thus, we drop all these columns. Furthermore, as we have seen before, there are null values in the `track_name`, `track_artist` , and `track_album_name` columns. Therefore, we need to drop the corresponding rows as well.\n"
      ],
      "id": "8f0c7b62"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_songs.dropna(subset=['track_name','track_artist','track_album_name'], inplace=True) # Drop null values from the data\n",
        "spotify_songs = spotify_songs.loc[:,'playlist_genre':'tempo'] # drop unnecessary columns\n",
        "spotify_songs = spotify_songs.drop('playlist_subgenre',axis=1) # drop unnecessary columns"
      ],
      "id": "7a44d149",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can verify that the null values have been dropped by calling the `.info()` method again.\n"
      ],
      "id": "9fe2e6a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_songs.info()"
      ],
      "id": "d24cabf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will use `StandardScaler` transformer to standardize our attributes. Notice that the `spotify_features` dataframe in the following code does not include the `loudness` attribute.\n"
      ],
      "id": "ecef7b8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import boxcox\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "spotify_features = spotify_songs.loc[:,['danceability','energy','speechiness','acousticness','instrumentalness','liveness','valence','tempo']] # collecting all the important features in a dataframe\n",
        "spotify_songs.loc[:,['danceability','energy','speechiness','acousticness','instrumentalness','liveness','valence','tempo']] = std_scaler.fit_transform(spotify_features)\n",
        "\n",
        "# Using boxcox to scale heavy-tailed features\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "spotify_new_features = spotify_songs.loc[:,'speechiness':'liveness']\n",
        "spotify_tail_features = min_max_scaler.fit_transform(spotify_new_features)\n",
        "spotify_tail_features = pd.DataFrame(spotify_tail_features,columns=spotify_new_features.columns)\n",
        "transformed_acousticness = boxcox(spotify_tail_features.acousticness,0.25) \n",
        "spotify_songs.acousticness = transformed_acousticness\n",
        "transformed_liveness = boxcox(spotify_tail_features.acousticness,0.25)\n",
        "spotify_songs.liveness = transformed_liveness\n",
        "transformed_instrumentalness = boxcox(spotify_tail_features.instrumentalness,0.2) \n",
        "spotify_songs.instrumentalness = transformed_instrumentalness\n",
        "transformed_speechiness = boxcox(spotify_tail_features.speechiness,0.2)\n",
        "spotify_songs.speechiness = transformed_speechiness"
      ],
      "id": "5c5c37f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can take a look at the feature distributions. As we can see, the attributes are on the same scale and many of them are centered around zero. Most of these distributions are Gaussian.\n"
      ],
      "id": "01bb32de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "spotify_features = spotify_songs.loc[:,['danceability','energy','speechiness','acousticness','instrumentalness','liveness','valence','tempo']]\n",
        "spotify_features.hist(figsize=(12, 8))\n",
        "plt.show()"
      ],
      "id": "96b7c83e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Training and Test Sets\n",
        "\n",
        "Now, we will create training and test sets. We will do this by limiting the test set size to 20 % of the total data set. Since we need an equal distribution of our target labels (i.e., the playlist genres), we will need to stratify the data with respect to the playlist genres.\n"
      ],
      "id": "3bd657ac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(spotify_songs, test_size=0.2, stratify = spotify_songs.playlist_genre,random_state=42)\n",
        "\n",
        "X_train = train_set.drop('playlist_genre',axis=1)\n",
        "y_train = train_set['playlist_genre']\n",
        "X_test = test_set.drop('playlist_genre',axis=1)\n",
        "y_test = test_set['playlist_genre']"
      ],
      "id": "d6f011a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the models\n",
        "\n",
        "Since this is a [multiclass classification problem](https://scikit-learn.org/stable/modules/multiclass.html#:~:text=Multiclass%20classification%20is%20a%20classification,an%20apple%2C%20or%20a%20pear.), support vector classifiers do not scale very well. Therefore, we will look for other classifiers. First, we'll try logistic regression.\n"
      ],
      "id": "0b3eca9e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_clf.fit(X_train, y_train); # Train the model"
      ],
      "id": "df3c5af7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To measure the performance of the classifier, we will first import the `cross_val_score` function from scikit learn.\n"
      ],
      "id": "8f6a3cce"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(log_clf,X_train,y_train,cv=3,scoring='accuracy')"
      ],
      "id": "2e4cb597",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the 3 validation folds, Logistic Regression predicts the correct genres with 45 % accuracy on average. Let us compare this performance with a dummy classifier.\n"
      ],
      "id": "d535b8ce"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier()\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "\n",
        "cross_val_score(dummy_clf, X_train, y_train, cv=3,scoring='accuracy')"
      ],
      "id": "be800faf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dummy classifier predicts the correct genre with 18 % accuracy. The Logistic Regression model is a little better than the dummy classifier for our data. Let us use the `DecisionTreeClassifier` next. We will use `RandomizedSeachCV` to select the optimum number of `max_feature`s in order to produce the best validation score.\n"
      ],
      "id": "f1072289"
    },
    {
      "cell_type": "code",
      "metadata": {
        "freeze": true
      },
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.stats import randint\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "param_random = {'max_features':randint(low=2,high=20)}\n",
        "random_search_tree = RandomizedSearchCV(decision_tree_clf,param_distributions=param_random,n_iter=10,cv=5,scoring='accuracy')\n",
        "random_search_tree.fit(X_train, y_train)\n",
        "\n",
        "cross_val_score(random_search_tree, X_train, y_train, cv=3,scoring='accuracy')"
      ],
      "id": "738cf41d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `DecisionTreeClassifier` produces an average accuracy of 41 % on the validation folds. We will import the `RandomForestClassifier` , which aggregates a large number of decision trees together.\n"
      ],
      "id": "cbf1370c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "freeze": true
      },
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest_clf = RandomForestClassifier(n_jobs=-1,random_state=42)\n",
        "param_random = [{'n_estimators':randint(low=100, high=500)},{'max_leaf_nodes':randint(low=5,high=20)}]\n",
        "random_search_forest = RandomizedSearchCV(random_forest_clf,param_distributions=param_random,n_iter=10,cv=3,scoring='accuracy')\n",
        "random_search_forest.fit(X_train,y_train)\n",
        "\n",
        "cross_val_score(random_search_forest, X_train, y_train, cv=3,scoring='accuracy')"
      ],
      "id": "3e5a7648",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `RandomForestClassifier` does better than the other models with an average accuracy of 53 % on the validation folds. Let us go one step further by using the `AdaBoostClassifier` with the `RandomForestClassifier` as the base estimator with a `learning_rate` of 0.5.\n"
      ],
      "id": "16e791c6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "freeze": true
      },
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "best_estimator = random_search_forest.best_estimator_\n",
        "ada_boost = AdaBoostClassifier(best_estimator,n_estimators=5,learning_rate = 0.5, random_state=42)\n",
        "ada_boost.fit(X_train, y_train)\n",
        "cross_val_score(ada_boost, X_train, y_train, cv=3,scoring='accuracy')"
      ],
      "id": "488a7059",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `AdaBoostClassifier` actually does slightly worse than the `RandomForestClassifier` on the validation folds. Therefore, let us use the `RandomForestClassifier` for the rest of our analysis. Firstly, let us measure the accuracy of the `RandomForestClassifier` on the test set.\n"
      ],
      "id": "1b02d613"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "\n",
        "random_search_forest.score(X_test, y_test) # print the accuracy score on the test set"
      ],
      "id": "8279f9c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This classifier has an accuracy score of 53.7 % on the test set.\n",
        "\n",
        "## Error Analysis\n",
        "\n",
        "The code below produces a Confusion Matrix for the `RandomForestClassifier`. As shown in the confusion matrix, many `edm` tracks (14 %) have been misclassified as `pop`. 16 % of the `latin` tracks have been misclassified as `pop` and `rap` each. Similarly, 17 % of `pop` tracks have been misclassified as `edm` and `r&b` each. 21 % of `r&b` tracks have been misclassified. These misclassifications have been caused due to similarities in the genres themselves. For instance, many `r&b` and `rap` songs have similarity `danceability` and `speechiness`. Further data collection is needed to differentiate the genres adequately.\n"
      ],
      "id": "f2be2ed7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "y_preds = cross_val_predict(random_search_forest.best_estimator_,X_train, y_train, cv=3)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_train,y_scores,normalize='true',values_format='.0%') # normalize predictions by row\n",
        "plt.show()"
      ],
      "id": "112e51c4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}