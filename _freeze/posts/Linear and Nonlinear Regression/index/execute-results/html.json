{
  "hash": "7799f553a656bdd4d778ba69d06485f9",
  "result": {
    "markdown": "---\ntitle: \"Linear and Nonlinear Regression\"\nauthor: \"Shrikar Banagiri\"\ndate: \"2023-11-08\"\nimage: \"image.jpg\"\nexecute: \n  echo: false\n  freeze: true\n---\n\n## Introduction\n\nThe [Bike Sharing Dataset](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) compiles the hourly and daily counts of rental bikes between 2011 and 2012. There are two .csv files: hour.csv and day.csv. These files have the following 15 features:\n\n-   `dteday`: The date.\n\n-   `season`: season (1 represents winter, 2 represents spring, 3 represents summer, 4 represents fall).\n\n-   `yr`: year (0 represents 2011, 1 represents 2012).\n\n-   `mnth`: month (1 to 12).\n\n-   `hr`: hour (0 to 23).\n\n-   `holiday`: whether day is a holiday or not (0 represents not a holiday, 1 represents a holiday).\n\n-   `weekday`: the day of the week (0 for Sunday and 6 Saturday).\n\n-   `workingday`: if working day, the value is 1; else the value is 0.\n\n-   `weathersit`: 1 represents clear weather, 2 represents mist / mist + broken clouds / mist + few clouds, 3 represents light snow / light rain, 4 represents heavy rain + thunderstorm + ice pallets / snow + fog.\n\n-   `temp`: this represents the normalized temperature in $^{\\circ}$C.\n\n-   `atemp`: this represents the normalized \"feels like\" temperature in $^{\\circ}$C.\n\n-   `hum`: Normalized humidity, ranges from 0 - 1.\n\n-   `windspeed`: Normalized windspeed, ranges from 0 - 1.\n\n-   `casual`: the number of casual bikers.\n\n-   `registered`: the number of registered bikers.\n\n-   `cnts`: the total number of casual and registered bikes.\n\nThe problem statement is to predict the total number of both casual and registered bikes `cnts` given the values of the rest of the features.\n\n## Importing the dataset\n\nThe dataset is hosted on the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/). First, we import the libraries required to perform the analysis.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Import the libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport urllib.request\nfrom pathlib import Path\nimport os\nimport zipfile\n\n# Downloading and opening the dataset\n\ncsv_path = Path('datasets/bike+sharing+dataset.zip') # store the dataset in a local folder\nurl = 'https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip' # url to download the dataset\n\nif not csv_path.is_file(): # check if the dataset directory exists. \n  Path(\"datasets\").mkdir(parents=True,exist_ok=True) # Create the directory\n  urllib.request.urlretrieve(url, csv_path)\n  with zipfile.ZipFile(csv_path) as bike_file:\n    bike_file.extractall(path='datasets')\n    \nbike_sharing_day = pd.read_csv(Path('datasets/day.csv')) \nbike_sharing_hour = pd.read_csv(Path('datasets/hour.csv')) # Store the dataset in a variable\n```\n:::\n\n\n## Analyzing the data\n\nLet us survey the data by using the `info()` method below. As we can see, there are no null entries in this dataset.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nbike_sharing_hour.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17379 entries, 0 to 17378\nData columns (total 17 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   instant     17379 non-null  int64  \n 1   dteday      17379 non-null  object \n 2   season      17379 non-null  int64  \n 3   yr          17379 non-null  int64  \n 4   mnth        17379 non-null  int64  \n 5   hr          17379 non-null  int64  \n 6   holiday     17379 non-null  int64  \n 7   weekday     17379 non-null  int64  \n 8   workingday  17379 non-null  int64  \n 9   weathersit  17379 non-null  int64  \n 10  temp        17379 non-null  float64\n 11  atemp       17379 non-null  float64\n 12  hum         17379 non-null  float64\n 13  windspeed   17379 non-null  float64\n 14  casual      17379 non-null  int64  \n 15  registered  17379 non-null  int64  \n 16  cnt         17379 non-null  int64  \ndtypes: float64(4), int64(12), object(1)\nmemory usage: 2.3+ MB\n```\n:::\n:::\n\n\nLet us now look at the counts of the individual dates.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nbike_sharing_hour['dteday'].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\ndteday\n2011-01-01    24\n2012-04-03    24\n2012-04-28    24\n2012-04-29    24\n2012-04-30    24\n              ..\n2011-01-26    16\n2011-01-18    12\n2012-10-30    11\n2011-01-27     8\n2012-10-29     1\nName: count, Length: 731, dtype: int64\n```\n:::\n:::\n\n\nAs shown in the value counts of the dates, not all hours of all dates are recorded. For example, on 29 October 2012, data for only one hour is available. Furthermore, we need to convert the `dteday` column into a `datetime` format. Furthermore, we will split the dates into separate columns comprising days, months, and years.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nbike_sharing_hour['dteday'] = pd.to_datetime(bike_sharing_hour['dteday']) # convert to date time format\nbike_sharing_hour['day'] = bike_sharing_hour['dteday'].dt.day # split into days\nbike_sharing_hour = bike_sharing_hour.drop('dteday',axis=1) # Drop the dteday column\n```\n:::\n\n\nNext, drop the irrelevant and redundant features. The `instant` column just represents an index, `atemp` is just a modification of the `temp` feature, `casual` and `rental` are just subsets of the `cnt` feature. `holiday` and `weekday` are together described by the feature `workingday.` Thus, we will drop all these features.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nbike_sharing_hour = bike_sharing_hour.drop(['instant','holiday','weekday','atemp','casual','registered'],axis=1) # drop the irrelevant columns\n```\n:::\n\n\nLet us now look at the correlation matrix for this dataset.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ncorr_matrix = bike_sharing_hour.corr() # correlation matrix\ncorr_matrix['cnt'].sort_values(ascending=False) # see the linear correlation values for the counts feature\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\ncnt           1.000000\ntemp          0.404772\nhr            0.394071\nyr            0.250495\nseason        0.178056\nmnth          0.120638\nwindspeed     0.093234\nworkingday    0.030284\nday          -0.004312\nweathersit   -0.142426\nhum          -0.322911\nName: cnt, dtype: float64\n```\n:::\n:::\n\n\nAs shown in the matrix, the `day` feature has a very weak correlation with the `cnt` feature. Thus, we can drop this feature\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nbike_sharing_hour = bike_sharing_hour.drop('day',axis=1)\n```\n:::\n\n\nLet us look at the correlation matrix for our dataframe now.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ncorr = bike_sharing_hour.corr() # correlation matrix\nsns.heatmap(corr,cmap='coolwarm')\nplt.title('Linear Correlations between attributes')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=609 height=495}\n:::\n:::\n\n\nFrom the correlation matrix, we can see that the features `season` and `mnth` are highly correlated with each other. Thus, we can drop one of these features. We will drop the `mnth` feature. Furthermore, as shown in the violinplot below, `season` is very well correlated with the `cnt` . Season 3 (Summer) has the highest number of median bike rentals.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nbike_sharing_hour = bike_sharing_hour.drop('mnth',axis=1) # drop the month feature from the dataset\n```\n:::\n\n\n::: {.cell execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){width=602 height=429}\n:::\n:::\n\n\nSince we have categorical attributes in our dataset, we will need to do one hot encoding as shown below.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\nbike_cats = bike_sharing_hour[['season','weathersit']] # categorical columns segregation\ncat_array_encoded = cat_encoder.fit_transform(bike_cats)\nbike_cats_encoded = pd.DataFrame(cat_array_encoded.toarray(),columns=cat_encoder.get_feature_names_out()) # encoded dataframe\n\nframes = [bike_sharing_hour, bike_cats_encoded]\nbike_sharing_hour_encoded = pd.concat(frames,axis=1) # encode the categorical variable in the original data frame\nbike_sharing_hour_encoded = bike_sharing_hour_encoded.drop(['season','weathersit'],axis=1) # drop redundant columns\n```\n:::\n\n\nLet us look at the distributions of the non-categorical features in the dataset.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nbike_features = bike_sharing_hour_encoded[['temp','hum','windspeed']] # non-categorical features in the DataFrame\nbike_features.hist(bins=50) # histogram\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\narray([[<Axes: title={'center': 'temp'}>,\n        <Axes: title={'center': 'hum'}>],\n       [<Axes: title={'center': 'windspeed'}>, <Axes: >]], dtype=object)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-2.png){width=588 height=431}\n:::\n:::\n\n\nAs we can see from the distributions, the `temp` feature has a gaussian like distribution whereas `hum` and `windspeed` are not gaussian. Thus, we will use the `StandardScaler` and `boxcox` transformer were used to transform these features.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import boxcox\nfrom sklearn.preprocessing import MinMaxScaler\n\nmin_max_scaler = MinMaxScaler(feature_range=(1,2))\nstd_scaler = StandardScaler()\n\nbike_sharing_hour_encoded[['windspeed']] = min_max_scaler.fit_transform(bike_sharing_hour_encoded[['windspeed']])\nbike_sharing_hour_encoded[['windspeed']] = boxcox(bike_sharing_hour_encoded[['windspeed']],0)\nbike_sharing_hour_encoded[['hum']] = boxcox(bike_sharing_hour_encoded[['hum']],0.5) # boxcox transform to scale hum feature\nbike_sharing_hour_encoded[['temp']] = std_scaler.fit_transform(bike_sharing_hour_encoded[['temp']])\nbike_sharing_hour_encoded[['hum']] = std_scaler.fit_transform(bike_sharing_hour_encoded[['hum']])\nbike_sharing_hour_encoded[['windspeed']] = std_scaler.fit_transform(bike_sharing_hour_encoded[['windspeed']])# Standardize the features\n\nbike_features = bike_sharing_hour_encoded[['temp','hum','windspeed']]\nbike_features.hist(bins=50) # histogram\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\narray([[<Axes: title={'center': 'temp'}>,\n        <Axes: title={'center': 'hum'}>],\n       [<Axes: title={'center': 'windspeed'}>, <Axes: >]], dtype=object)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-2.png){width=585 height=431}\n:::\n:::\n\n\nThe histograms now show a fairly gaussian distribution except for a few outliers in the `hum` feature. Let us remove these outliers.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nhum_outliers = bike_sharing_hour_encoded[bike_sharing_hour_encoded.hum == -6.0] # outliers in the humidity features\nbike_new = bike_sharing_hour_encoded.merge(hum_outliers,how='left',indicator=True) \nbike_new = bike_new[bike_new['_merge']=='left_only']\n\nbike_new = bike_new.drop(['_merge'],axis=1)\nbike_sharing_hour_encoded = bike_new # removed humidity outliers\n\nbike_features = bike_sharing_hour_encoded[['temp','hum','windspeed']]\nbike_features.hist(bins=50) # plot histogram again\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\narray([[<Axes: title={'center': 'temp'}>,\n        <Axes: title={'center': 'hum'}>],\n       [<Axes: title={'center': 'windspeed'}>, <Axes: >]], dtype=object)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=585 height=431}\n:::\n:::\n\n\n## Creating Training and Test sets\n\nNow, let us create the training and test sets as shown below.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(bike_sharing_hour_encoded,test_size=0.2,random_state=42) # split the training and test sets\n\nX_train = train_set.drop('cnt',axis=1) # drop the target label from the training set\ny_train = train_set['cnt'] # target label\nX_test = test_set.drop('cnt',axis=1) # drop the target label from the test set\ny_test = test_set['cnt'] # target label\n```\n:::\n\n\n## Training the models\n\nFor this regression problem, let us use linear regression and non-linear regression models. Let us first try the simplest regression, the `LinearRegression`.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\nlin_reg = LinearRegression() \nlin_reg.fit(X_train,y_train) # Train the model\n\n-cross_val_score(lin_reg,X_train,y_train,cv=5,scoring='neg_root_mean_squared_error')\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\narray([138.25778269, 142.84438603, 139.61695447, 146.46972741,\n       141.99234977])\n```\n:::\n:::\n\n\nFor five-fold cross validation, `LinearRegression` produces a root mean squared error (RMSE) of about 140 on average. Let us look at the learning curve to see if the model is overfitting or underfitting the training data.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# import learning_curve to check if the model is overfitting or underfitting\n\nfrom sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, valid_scores = learning_curve(LinearRegression(), X_train, y_train, train_sizes=np.linspace(0.001, 1.0, 40), cv=5, scoring=\"neg_root_mean_squared_error\") # learning curve for different test sizes\n\ntrain_errors = -train_scores.mean(axis=1)\nvalid_errors = -valid_scores.mean(axis=1)\n\nplt.figure(figsize=(6, 4)) # plot the learning curve\nplt.plot(train_sizes, train_errors, \"r-+\", linewidth=2, label=\"train\")\nplt.plot(train_sizes, valid_errors, \"b-\", linewidth=3, label=\"valid\")\n\nplt.xlabel(\"Training set size\")\nplt.ylabel(\"RMSE\")\nplt.grid()\nplt.legend(loc=\"upper right\")\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=519 height=356}\n:::\n:::\n\n\nThe learning curve plot shows a classic case of the model underfitting the data. When the training set data size is low, the data can be described fairly accurately by a linear regression model. Therefore, the RMSE is low for lower training set size. However, as the training set data size increases, the value of RMSE steadily increases until it reaches a constant value. At the point, adding or removing the training data does not make the model better or worse. Similarly, for the validation sets, if the size of the data set is low, the validation error is very high. However, as more data is added, the validation drops down until it reaches a constant value.\n\nSince the model is underfitting, we will implement a higher degree polynomial regressor. We will import `PolynomialFeatures` from scikit-learn.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_features = PolynomialFeatures(degree=2,include_bias=False)\nX_poly_train = poly_features.fit_transform(X_train) # transform feature labels into the polynomial form\nlin_reg.fit(X_poly_train,y_train) # fit linear regression on the polynomially transformed variables\n\n-cross_val_score(lin_reg,X_poly_train,y_train,cv=5,scoring='neg_root_mean_squared_error') # the cross validation score\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\narray([119.09738289, 121.77779834, 121.89287345, 124.76923189,\n       120.9170965 ])\n```\n:::\n:::\n\n\nWe can see that the polynomial regressor has performed marginally better than the linear regressor with an average cross val score of 120 across the 5 folds. Let us plot the learning curve to see whether the model is overfitting or underfitting.\n\n::: {.cell execution_count=19}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-20-output-1.png){width=519 height=356}\n:::\n:::\n\n\nAs we can see from the learning curve, the regression model is still underfitting. Therefore, let us use nonlinear regressors instead. We will use `DecisionTreeRegressor` first. We will use `RandomizedSearchCV` to tune the hyperparameters.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\ndecision_reg = DecisionTreeRegressor(random_state=42)\nparam_random = [{'max_depth':randint(low=2,high=20)},{'min_samples_leaf':randint(low=2,high=20)}] # hyperparameter tuning\nrand_dec_reg = RandomizedSearchCV(decision_reg,param_distributions=param_random,scoring='neg_root_mean_squared_error',n_iter=10,random_state=42) \nrand_dec_reg.fit(X_train,y_train) # training the decision tree regressor\n\n-cross_val_score(rand_dec_reg,X_train,y_train,cv=5,scoring='neg_root_mean_squared_error')\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\narray([57.64518755, 59.89346893, 58.21764267, 56.4518072 , 61.12587745])\n```\n:::\n:::\n\n\nThe cross validation score for this model is close to 60 on average across the five validation folds. This score is much better than the linear and polynomial regressors. Let us look at the learning curve for this model.\n\n::: {.cell execution_count=21}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-22-output-1.png){width=519 height=356}\n:::\n:::\n\n\nThe validation error decreases as the training set size increases but the validation error never approaches the training error. Thus, the model seems to be slightly overfitting. Let us now implement the `RandomForestRegressor`.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\n\nrand_reg = RandomForestRegressor(random_state=42)\nparam_random = [{'n_estimators':randint(low=20,high=100)}] # hyperparameter tuning\nrandom_rand_reg = RandomizedSearchCV(rand_reg,param_distributions=param_random,scoring='neg_root_mean_squared_error',n_iter=10,random_state=42) \nrandom_rand_reg.fit(X_train,y_train) # training the decision tree regressor\n\n-cross_val_score(random_rand_reg,X_train,y_train,cv=3,scoring='neg_root_mean_squared_error')\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\narray([51.27749959, 48.82450026, 51.86218269])\n```\n:::\n:::\n\n\nThe `RandomForestRegressor` produces a cross validation score of 50 on average across the three validation folds. Thus, the `RandomForestRegressor` performs the best among all the models tested here. Let us look at the root mean log squared error (RMLSE) for the test set using this model.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nfrom sklearn.metrics import mean_squared_log_error\n\ny_pred = random_rand_reg.predict(X_test) # predictions on the test set\nnp.sqrt(mean_squared_log_error(y_pred,y_test))\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n0.3858129750838661\n```\n:::\n:::\n\n\nThe RMLSE of the `RandomForestRegressor` is 0.386.\n\n## Feature Importances\n\nLet us look at how the RandomForestRegressor weighs the features in predictions. As shown in the bar plot below, the hour of the day is the most important feature for the Random Forest model.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nimportances = random_rand_reg.best_estimator_.feature_importances_\nplt.title('Feature Importances for the Random Forest Model')\nplt.barh(range(len(importances)), importances, color='g', align='center')\nplt.yticks(range(len(importances)), X_train.columns)\nplt.xlabel('Relative Weights')\nplt.grid()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-25-output-1.png){width=635 height=449}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}